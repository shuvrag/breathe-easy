{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/combined_data_1hr_lags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2184, 104)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Conc.</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Gust</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Precip.</th>\n",
       "      <th>Condition</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour_20</th>\n",
       "      <th>Hour_21</th>\n",
       "      <th>Hour_22</th>\n",
       "      <th>Hour_23</th>\n",
       "      <th>Day_Mon</th>\n",
       "      <th>Day_Sat</th>\n",
       "      <th>Day_Sun</th>\n",
       "      <th>Day_Thu</th>\n",
       "      <th>Day_Tue</th>\n",
       "      <th>Day_Wed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date (LT)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-19 22:00:00</th>\n",
       "      <td>69.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-19 23:00:00</th>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-20 00:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Raw Conc.  Temperature  Dew Point  Humidity  Wind  \\\n",
       "Date (LT)                                                                \n",
       "2019-10-19 22:00:00       69.0         77.0       75.0      94.0  67.5   \n",
       "2019-10-19 23:00:00       75.0         77.0       75.0      94.0  22.5   \n",
       "2019-10-20 00:00:00       90.0         77.0       75.0      94.0   0.0   \n",
       "\n",
       "                     Wind Speed  Wind Gust  Pressure  Precip.  Condition  ...  \\\n",
       "Date (LT)                                                                 ...   \n",
       "2019-10-19 22:00:00         3.0        0.0     29.87      0.0        1.0  ...   \n",
       "2019-10-19 23:00:00         3.0        0.0     29.87      0.0        1.0  ...   \n",
       "2019-10-20 00:00:00         0.0        0.0     29.90      0.0        2.0  ...   \n",
       "\n",
       "                     Hour_20  Hour_21  Hour_22  Hour_23  Day_Mon  Day_Sat  \\\n",
       "Date (LT)                                                                   \n",
       "2019-10-19 22:00:00        0        0        1        0        0        1   \n",
       "2019-10-19 23:00:00        0        0        0        1        0        1   \n",
       "2019-10-20 00:00:00        0        0        0        0        0        0   \n",
       "\n",
       "                     Day_Sun  Day_Thu  Day_Tue  Day_Wed  \n",
       "Date (LT)                                                \n",
       "2019-10-19 22:00:00        0        0        0        0  \n",
       "2019-10-19 23:00:00        0        0        0        0  \n",
       "2019-10-20 00:00:00        1        0        0        0  \n",
       "\n",
       "[3 rows x 132 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {\"Unnamed: 0\": \"Date\"}, inplace = True) \n",
    "df = df.set_index('Date (LT)')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.dropna(inplace = True) \n",
    "df = pd.get_dummies(df, columns = ['Month', 'Hour', 'Day'], drop_first = True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63832799 0.56129214 0.56182336 0.50438627 0.57728804]\n",
      "0.6732676175407878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1740.020755048043"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regular old linear regression\n",
    "reg = LinearRegression()\n",
    "#remove variables I want to predict\n",
    "X = df.drop(['Raw Conc.+1', 'Raw Conc.+2', 'Raw Conc.+3', 'Raw Conc.+4', 'Raw Conc.+5', 'Raw Conc.+6'], axis = 1)\n",
    "#normalize with this method so I can normalize the input for predictions later on\n",
    "X_norm = preprocessing.normalize(X)\n",
    "#set y as the variables I want to predict\n",
    "y = df[['Raw Conc.+1', 'Raw Conc.+2', 'Raw Conc.+3', 'Raw Conc.+4', 'Raw Conc.+5', 'Raw Conc.+6']]\n",
    "#split data into test/train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3, random_state = 21)\n",
    "#fit model on training data\n",
    "reg.fit(X_train, y_train)\n",
    "#predict output from test set\n",
    "y_pred = reg.predict(X_test)\n",
    "#check how variable my results are with different test-train splits\n",
    "cv_results = cross_val_score(reg, X, y, cv = 5)\n",
    "print(cv_results)\n",
    "#look at r-squared comparting predicted values to actual values\n",
    "print(r2_score(y_test, y_pred))\n",
    "#look at MSE, better for my purposed because there are harsher penalties for being off by a lot\n",
    "#I want to capture outliers - high PM days - so use MSE\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data set for test and train\n",
    "X = df.drop(['Raw Conc.+1', 'Raw Conc.+2', 'Raw Conc.+3', 'Raw Conc.+4', 'Raw Conc.+5', 'Raw Conc.+6'], axis = 1)\n",
    "y = df[['Raw Conc.+1', 'Raw Conc.+2', 'Raw Conc.+3', 'Raw Conc.+4', 'Raw Conc.+5', 'Raw Conc.+6']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning - check for max depth and n estimators\n",
    "rfr = RandomForestRegressor()\n",
    "param_dist = {\"max_depth\": [3, 5, None],\n",
    "              \"n_estimators\": [10, 50, 100, 500, 1000]}\n",
    "\n",
    "n_iter_search = 5\n",
    "random_search = RandomizedSearchCV(rfr, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False, \n",
    "                                   random_state = 0, scoring = \"neg_mean_squared_error\")\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_params_\n",
    "# results show:   {'n_estimators': 1000, 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.732791956689866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "\n",
    "# Fit Decision Tree Model\n",
    "exam_model = dtr(random_state = 1)\n",
    "exam_model.fit(X_train,y_train)\n",
    "\n",
    "# Predict using DTM\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "val_fin = exam_model.predict(X_test)\n",
    "\n",
    "# Display MAE\n",
    "print(mae(y_test, val_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuvr\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.28054911059552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(126,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Fit Random Forest Model\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using RFM\n",
    "melb_preds = forest_model.predict(X_test)\n",
    "\n",
    "# Display MAE\n",
    "print(mean_absolute_error(y_test, melb_preds))\n",
    "\n",
    "#print(len(X_train[0]))\n",
    "#print (type(X_test))\n",
    "#X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "# save the model to disk\n",
    "filename = 'finalised_model.sav'\n",
    "pickle.dump(forest_model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#result = loaded_model.score(X_test, y_test)\n",
    "#print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-19 23:00:00\n",
      "1\n",
      "2019-10-19 23:00:00\n"
     ]
    }
   ],
   "source": [
    "dt = pd.to_datetime('2019-10-19 23:00:00')\n",
    "print (dt)\n",
    "\n",
    "print (df.index.get_loc(dt, method='nearest'))\n",
    "\n",
    "idx = df.index[df.index.get_loc(dt, method='nearest')]\n",
    "print (idx)\n",
    "\n",
    "#df.columns[-1]\n",
    "#df.loc[dt,:'Day_Wed'].index#.index\n",
    "#df.loc[dt].values[0]\n",
    "#print(df.loc[[2019-10-19 23:00:00]])\n",
    "\n",
    "input_datetime = pd.to_datetime('2019-11-21 07:00:00')\n",
    "print(input_datetime)\n",
    "type(input_datetime)\n",
    "#input_datetime = datetime.strftime('2019-11-21 07:00:00', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-23 07:00:00\n",
      "895\n",
      "179.0\n",
      "173.0\n",
      "162.0\n",
      "202.0\n",
      "202.0\n",
      "218.0\n",
      "[179.    70.    57.    64.    90.     7.     0.    29.98   0.     1.\n",
      " 163.    66.    61.    83.   112.5    9.     0.    30.01   0.     2.\n",
      " 157.    64.    59.    83.    90.     8.     0.    30.04   0.     2.\n",
      " 168.    63.    57.    82.    67.5    9.     0.    30.04   0.     2.\n",
      " 173.    70.    61.    73.    90.     9.     0.    29.96   0.     1.\n",
      " 162.    70.    61.    73.   112.5    9.     0.    29.96   0.     1.\n",
      " 202.    70.    61.    73.    90.     8.     0.    29.96   0.     1.\n",
      " 202.    68.    61.    78.    90.     7.     0.    29.93   0.     1.\n",
      " 218.    66.    59.    78.    90.     5.     0.    29.96   0.     1.\n",
      " 228.    64.    61.    88.    90.     5.     0.    29.96   0.     2.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     1.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.  ]\n",
      "2019-11-21 07:00:00\n",
      "DatetimeIndex(['2019-10-19 22:00:00', '2019-10-19 23:00:00',\n",
      "               '2019-10-20 00:00:00', '2019-10-20 01:00:00',\n",
      "               '2019-10-20 02:00:00', '2019-10-20 03:00:00',\n",
      "               '2019-10-20 04:00:00', '2019-10-20 05:00:00',\n",
      "               '2019-10-20 06:00:00', '2019-10-20 07:00:00',\n",
      "               ...\n",
      "               '2020-01-18 03:00:00', '2020-01-18 04:00:00',\n",
      "               '2020-01-18 05:00:00', '2020-01-18 06:00:00',\n",
      "               '2020-01-18 07:00:00', '2020-01-18 08:00:00',\n",
      "               '2020-01-18 09:00:00', '2020-01-18 10:00:00',\n",
      "               '2020-01-18 11:00:00', '2020-01-18 12:00:00'],\n",
      "              dtype='datetime64[ns]', name='Date (LT)', length=1435, freq=None)\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "input_datetime = pd.to_datetime('2019-12-23 07:00:00')\n",
    "print(input_datetime)\n",
    "\n",
    "\n",
    "index = df.index.get_loc(input_datetime, method='nearest')\n",
    "print(index)\n",
    "\n",
    "#print(df.loc[input_datetime].values[0])\n",
    "\n",
    "#st.write(df.loc[input_datetime].values)\n",
    "#+ timedelta(hours=9)\n",
    "\n",
    "for i in range(6):\n",
    "    print(df.loc[input_datetime + timedelta(hours=i)].values[0])\n",
    "\n",
    "print(df.loc[input_datetime].values)\n",
    "\n",
    "type(df.loc[input_datetime].values)\n",
    "len(df.loc[input_datetime].values)\n",
    "\n",
    "input_datetime = pd.to_datetime('2019-11-21 07:00:00')\n",
    "print(input_datetime)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-19 23:00:00\n",
      "[283.9 269.6 275.6 259.7 259.7 249.2]\n"
     ]
    }
   ],
   "source": [
    "dt = pd.to_datetime('2019-10-19 23:00:00')\n",
    "\n",
    "input_datetime = pd.to_datetime('2019-10-19 23:00:00')\n",
    "print(input_datetime)\n",
    "\n",
    "#From later \n",
    "#print (df.index.get_loc(dt, method='nearest'))\n",
    "\n",
    "#idx = df.index[df.index.get_loc(dt, method='nearest')]\n",
    "#print (idx)\n",
    "\n",
    "#df.columns[-1]\n",
    "#df.loc[dt,:'Day_Wed'].index#.index\n",
    "#df.loc[dt].values[0]\n",
    "#print(df.loc[[2019-10-19 23:00:00]])\n",
    "\n",
    "input = np.delete(df.loc[input_datetime].values, [40,50,60,70,80,90])\n",
    "output=loaded_model.predict([input])\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
